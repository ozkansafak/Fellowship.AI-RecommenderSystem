{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15507908137205311183\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 384172032\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 12304149911870337944\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0\"\n",
      "]\n",
      "tensorflow version: 1.0.0\n",
      "python version: 3.6.1 |Continuum Analytics, Inc.| (default, May 11 2017, 13:09:58) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "python executable location: /home/aind2/anaconda3/envs/aind-dog/bin/python\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (helpers.py, line 136)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/aind2/anaconda3/envs/aind-dog/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2862\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-1a97f2e304da>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from helpers import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/aind2/miscelleneous_projects/fellowship.ai/ml-20m/helpers.py\"\u001b[0;36m, line \u001b[0;32m136\u001b[0m\n\u001b[0;31m    <<<<<<< HEAD\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# I like to start by checking if the GPU was initiated succesfully,\n",
    "# and by seeing the tensroflow and python versions being used\n",
    "# by the notebook.\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import tensorflow as tf, sys\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "print('tensorflow version: %s' % tf.__version__)\n",
    "print('python version: %s' % sys.version)\n",
    "print('python executable location: %s' % sys.executable)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helpers import *\n",
    "import os, sys, tarfile, time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import pickle\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'font.size'      : 11,\n",
    "          'figure.figsize' : (17, 6),\n",
    "          'axes.labelsize' : 'x-large',\n",
    "          'axes.titlesize' : 'x-large',\n",
    "          'axes.grid'      : 'on',\n",
    "          'xtick.labelsize': 'x-large',\n",
    "          'ytick.labelsize': 'x-large'}\n",
    "\n",
    "pylab.rcParams.update(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Lab41 dataset into: train_Y, cv_Y, test_Y\n",
    "#                          train_Y_indices, cv_Y_indices, test_Y_indices\n",
    "\n",
    "start = time.time()\n",
    "#...................................................\n",
    "train_Y_indices, train_Y, cv_Y_indices, \\\n",
    "        cv_Y, test_Y_indices, test_Y, \\\n",
    "        n_users, n_movies, u_mean_dict, v_mean_dict = read_and_split_data()\n",
    "\n",
    "ax = plt.subplot(131)\n",
    "ax.hist(np.concatenate((train_Y, cv_Y, test_Y)), bins=np.arange(-.25, 5.25, 0.5), alpha=.6, \\\n",
    "         edgecolor='black', linewidth=2, normed=True);\n",
    "ax.set_title('histogram of Lab41 ratings');\n",
    "\n",
    "#...................................................\n",
    "\n",
    "ax = plt.subplot(132)\n",
    "ax.hist((list(u_mean_dict.values())), bins=np.arange(-.25, 5.25, 0.5), alpha=.6, \\\n",
    "        color='red', edgecolor='black', linewidth=2, normed=True);\n",
    "ax.set_title('user mean ratings');\n",
    "\n",
    "ax = plt.subplot(133)\n",
    "\n",
    "ax.hist((list(v_mean_dict.values())), bins=np.arange(-.25, 5.25, 0.5), alpha=.6, \\\n",
    "        color='black', edgecolor='black', linewidth=2, normed=True);\n",
    "ax.set_title('movie mean ratings');\n",
    "\n",
    "\n",
    "print_runtime(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_u_mean(train_Y_indices, u_mean_dict, v_mean_dict):\n",
    "    N = train_Y_indices.shape[0]\n",
    "    train_u_mean = np.zeros((N, 1))\n",
    "    train_v_mean = np.zeros((N, 1))\n",
    "    for i in range(N):\n",
    "        u_idx = train_Y_indices[i,0]\n",
    "        v_idx = train_Y_indices[i,1]\n",
    "        train_u_mean[i] = u_mean_dict[u_idx]\n",
    "        train_v_mean[i] = v_mean_dict[v_idx]\n",
    "\n",
    "    return train_u_mean, train_v_mean\n",
    "\n",
    "start = time.time()\n",
    "train_u_mean, train_v_mean = get_train_u_mean(train_Y_indices, u_mean_dict, v_mean_dict)\n",
    "\n",
    "print_runtime(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "# BATCH_SIZE = 1024*16\n",
    "BATCH_SIZE_arr = [1024*16]\n",
    "# LAMBDA_ARR = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.001, 0.00125]\n",
    "LAMBDA = 0.01\n",
    "k = 10 # an important hyperparameter.\n",
    "lr = 0.005\n",
    "NUM_EPOCHS = 10\n",
    "if 'out.txt' in os.listdir(): \n",
    "    os.remove('out.txt')\n",
    "    \n",
    "for BATCH_SIZE in BATCH_SIZE_arr:\n",
    "    #.............................................. \n",
    "    train, loss, reg, Y_indices, Y, U, V, Y_pred, UV_xft, UU_xft, VV_xft, u_mean, v_mean  = \\\n",
    "                            construct_graph(LAMBDA, k, lr, BATCH_SIZE, n_users, n_movies)\n",
    "    #.............................................. \n",
    "\n",
    "    start = time.time()\n",
    "    mae_train_arr, mae_cv_arr, mae_test_arr, loss_arr, mean_preds, n_batches, preds, \\\n",
    "                   _U, _V, _UV_xft, _UU_xft, _VV_xft = \\\n",
    "                         train_the_model(Y_indices, Y, train_Y_indices, train_Y, BATCH_SIZE, \n",
    "                   NUM_EPOCHS, LAMBDA, k, lr, \n",
    "                   train, loss, reg, U, V, Y_pred,\n",
    "                   cv_Y, cv_Y_indices, test_Y, test_Y_indices,\n",
    "                   UV_xft, UU_xft, VV_xft, \n",
    "                   train_u_mean, train_v_mean, u_mean, v_mean)\n",
    "    #.............................................. \n",
    "    # plotting....\n",
    "    ax1, ax2 = plotter(mae_train_arr, mae_cv_arr, mae_test_arr, loss_arr, BATCH_SIZE)\n",
    "\n",
    "#.............................................. \n",
    "print_runtime(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1, ax2 = plotter(mae_train_arr, mae_cv_arr, mae_test_arr, loss_arr, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=plt.subplot(121)\n",
    "ax.plot(_UV_xft);\n",
    "ax=plt.subplot(122)\n",
    "ax.plot(_U);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # hyperparameters\n",
    "# # BATCH_SIZE = 1024*16\n",
    "# BATCH_SIZE_arr = [1024*128, 1024*64, 1024*32, 1024*16]\n",
    "# # LAMBDA_ARR = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009, 0.001, 0.00125]\n",
    "# LAMBDA = 0\n",
    "# k = 10 # an important hyperparameter.\n",
    "# lr = 0.01\n",
    "# NUM_EPOCHS = 30\n",
    "# if 'out.txt' in os.listdir(): \n",
    "#     os.remove('out.txt')\n",
    "    \n",
    "# for BATCH_SIZE in BATCH_SIZE_arr:\n",
    "#     #.............................................. \n",
    "#     train, loss, reg, Y_indices, Y, U, V, Y_pred, UV_xft, UU_xft, VV_xft = \\\n",
    "#                             construct_graph(LAMBDA, k, lr, BATCH_SIZE, n_users, n_movies)\n",
    "#     #.............................................. \n",
    "\n",
    "#     start = time.time()\n",
    "#     mae_train_arr, mae_cv_arr, mae_test_arr, loss_arr, mean_preds, n_batches, preds, \\\n",
    "#                    _U, _V, _UV_xft, _UU_xft, _VV_xft = \\\n",
    "#                          train_the_model(Y_indices, Y, train_Y_indices, train_Y, BATCH_SIZE, \n",
    "#                    NUM_EPOCHS, LAMBDA, k, lr, \n",
    "#                    train, loss, reg, U, V, Y_pred,\n",
    "#                    cv_Y, cv_Y_indices, test_Y, test_Y_indices,\n",
    "#                    UV_xft, UU_xft, VV_xft)\n",
    "#     #.............................................. \n",
    "#     # plotting....\n",
    "#     ax1, ax2 = plotter(mae_train_arr, mae_cv_arr, mae_test_arr, loss_arr, BATCH_SIZE)\n",
    "\n",
    "# #.............................................. \n",
    "# print_runtime(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1, ax2 = plotter(mae_train_arr, mae_cv_arr, mae_test_arr, loss_arr, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
