{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/cpu:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14614415894446553231\n",
      ", name: \"/gpu:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11324823962\n",
      "locality {\n",
      "  bus_id: 1\n",
      "}\n",
      "incarnation: 12437008016174268944\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0\"\n",
      "]\n",
      "\n",
      "........................................\n",
      "\n",
      "tensorflow version: 1.0.0\n",
      "python version: 3.6.1 |Continuum Analytics, Inc.| (default, May 11 2017, 13:09:58) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "python executable location: /home/aind2/anaconda3/envs/aind-dog/bin/python\n"
     ]
    }
   ],
   "source": [
    "# I like to start by checking if the GPU was initiated succesfully,\n",
    "# and by seeing the tensroflow and python versions being used\n",
    "# by the notebook.\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "import tensorflow as tf, sys\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "print('\\n' + '..'*20 + '\\n')\n",
    "print('tensorflow version: %s' % tf.__version__)\n",
    "print('python version: %s' % sys.version)\n",
    "print('python executable location: %s' % sys.executable)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from helpers import *\n",
    "import os, sys, tarfile, time\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'font.size'      : 10,\n",
    "          'figure.figsize' : (17, 3),\n",
    "          'axes.labelsize' : 'x-large',\n",
    "          'axes.titlesize' : 'x-large',\n",
    "          'axes.grid'      : 'on',\n",
    "          'xtick.labelsize': 'x-large',\n",
    "          'ytick.labelsize': 'x-large'}\n",
    "\n",
    "pylab.rcParams.update(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 1 min 24 sec\n"
     ]
    }
   ],
   "source": [
    "# Read the Lab41 dataset into \n",
    "# train_Y, cv_Y, test_Y\n",
    "# train_Y_indices, cv_Y_indices, test_Y_indices\n",
    "\n",
    "start = time.time()\n",
    "#...................................................\n",
    "\n",
    "RATINGS_PATH = './data_ml-20m/ratings.csv'\n",
    "MOVIES_PATH = './data_ml-20m/movies.csv'\n",
    "\n",
    "#...................................................\n",
    "\n",
    "with open(RATINGS_PATH) as f:\n",
    "    ratings = f.readlines()\n",
    "\n",
    "with open(MOVIES_PATH) as f:\n",
    "    movies = f.readlines()\n",
    "\n",
    "#...................................................\n",
    "\n",
    "from_mID_2_idx = {}\n",
    "for i, row in enumerate(movies[1:]):\n",
    "    mID = int(row.split(',')[0])\n",
    "    from_mID_2_idx[mID] = i\n",
    "    \n",
    "#...................................................\n",
    "\n",
    "n_users = 138493\n",
    "n_movies = len(movies[1:]) # n_movies = 27278\n",
    "\n",
    "N = len(ratings[1:])\n",
    "Y_indices = np.zeros((N,2), dtype=np.int32)\n",
    "Y = np.zeros(N)\n",
    "\n",
    "for i, row in enumerate(ratings[1:]):\n",
    "    uID, mID, yij = [e for e in row.split(',')[:-1]]\n",
    "    u_idx = int(uID) - 1\n",
    "    v_idx = from_mID_2_idx[int(mID)]\n",
    "    yij = float(yij)\n",
    "    \n",
    "    Y_indices[i] = [u_idx, v_idx]\n",
    "    Y[i] = yij\n",
    "\n",
    "#...................................................\n",
    "\n",
    "i1 = int(N*.64)\n",
    "i2 = int(N*.8)\n",
    "\n",
    "train_Y = Y[:i1]\n",
    "train_Y_indices = Y_indices[:i1]\n",
    "\n",
    "cv_Y = Y[i1:i2]\n",
    "cv_Y_indices = Y_indices[i1:i2]\n",
    "\n",
    "test_Y = Y[i2:]\n",
    "test_Y_indices = Y_indices[i2:]\n",
    "\n",
    "del Y, Y_indices\n",
    "\n",
    "print_runtime(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime: 0 min 0 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#..............................................\n",
    "BATCH_SIZE = 1024*16\n",
    "LAMBDA = 0.0001\n",
    "k = 10 \n",
    "\n",
    "Y = tf.placeholder(dtype=tf.float32, shape=(BATCH_SIZE,))\n",
    "Y_indices = tf.placeholder(dtype=tf.int32, shape=(BATCH_SIZE,2))\n",
    "\n",
    "# initialization of U and V is critical. \n",
    "# set mean=np.sqrt(mu/k) , where mu ~ 3 or 3.5\n",
    "U = tf.Variable(tf.truncated_normal(shape=(n_users,k), mean=np.sqrt(3.5/k), stddev=0.2), dtype=tf.float32)\n",
    "V = tf.Variable(tf.truncated_normal(shape=(n_movies,k), mean=np.sqrt(3.5/k), stddev=0.2), dtype=tf.float32)\n",
    "\n",
    "sliced_U, sliced_V = get_sliced_UV(Y_indices, Y, U, V, k, BATCH_SIZE)\n",
    "\n",
    "#..............................................     \n",
    "\n",
    "reg = LAMBDA*(tf.reduce_sum((U)**2) + tf.reduce_sum((V)**2)) / BATCH_SIZE / k\n",
    "loss = (tf.norm(Y - tf.reduce_sum(tf.multiply(sliced_U, sliced_V), axis=1))) / BATCH_SIZE + reg\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    "#.............................................. \n",
    "print_runtime(start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_batches: 781\n",
      "\n",
      "New epoch: 1 ******************************\n",
      "batch_no: 781, _loss: 0.008144455030560493  \n",
      "mae: 0.7930, _mae_test: 0.7889, mean_preds: 3.4806\n",
      "reg/_loss: 0.0445\n",
      "\n",
      "New epoch: 2 ******************************\n",
      "batch_no: 781, _loss: 0.007703713607043028  \n",
      "mae: 0.8349, _mae_test: 0.8322, mean_preds: 3.2432\n",
      "reg/_loss: 0.0447\n",
      "\n",
      "New epoch: 3 ******************************\n",
      "batch_no: 304, _loss: 0.007307210937142372  \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-250-c0ab898ed715>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroken\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             train_acc, _loss = sess.run([train, loss], \n\u001b[0;32m---> 18\u001b[0;31m                                       feed_dict={Y_indices : batch_Y_indices, Y : batch_Y})\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch_no: {}, _loss: {} \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aind-dog/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aind-dog/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aind-dog/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3/envs/aind-dog/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aind-dog/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#.............................................. \n",
    "NUM_EPOCHS = 20\n",
    "init = tf.global_variables_initializer()\n",
    "batch = Batch(train_Y_indices, train_Y, BATCH_SIZE=BATCH_SIZE)\n",
    "n_batches = len(train_Y) // BATCH_SIZE\n",
    "print('n_batches: {}'.format(n_batches))\n",
    "batch_no = 0\n",
    "mae = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    while not (batch.epoch == NUM_EPOCHS and batch.last_batch==True):\n",
    "        batch_no += 1\n",
    "        batch_Y_indices, batch_Y = batch.next()\n",
    "        if not batch.broken:\n",
    "            train_acc, _loss = sess.run([train, loss], \n",
    "                                      feed_dict={Y_indices : batch_Y_indices, Y : batch_Y})\n",
    "            print(\"batch_no: {}, _loss: {} \".format(batch_no, _loss), end='\\r') \n",
    "        else: \n",
    "           \n",
    "            batch_no = 0\n",
    "            _U, _V = sess.run([U, V], feed_dict={}) \n",
    "            preds, _mae = evaluate(cv_Y, cv_Y_indices, _U, _V, BATCH_SIZE)\n",
    "            _, _mae_test = evaluate(test_Y, test_Y_indices, _U, _V, BATCH_SIZE)\n",
    "            mae.append(_mae)\n",
    "            mean_preds = np.mean(preds)\n",
    "            print('\\nmae: %6.4f, _mae_test: %6.4f, mean_preds: %6.4f' % (_mae,_mae_test,mean_preds))\n",
    "            print('reg/_loss: %6.4f' %(sess.run(reg/_loss)))\n",
    "\n",
    "#.............................................. \n",
    "print_runtime(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
